{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from BeautifulSoup import *\n",
    "from urlparse import urljoin\n",
    "from pysqlite2 import dbapi2 as sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ignorewords = set(['the', 'of', 'to', 'and', 'a', 'in', 'is', 'it'])\n",
    "class crawler:\n",
    "    def __init__(self, dbname):\n",
    "        self.con = sqlite.connect(dbname)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.con.close()\n",
    "        \n",
    "    def dbcommit(self):\n",
    "        self.con.commit()\n",
    "        \n",
    "    def getentryid(self, table, field, value, createnew = True):\n",
    "        cur = slef.con.execute(\"select rowid from %s where %s = '%s' \" %(table, field, value) )\n",
    "        res = cur.fetchone()\n",
    "        if res == None:\n",
    "            cur = self.con.execute(\"insert into %s (%s) values ('%s')\" % (table, field, value))\n",
    "            return cur.lastrowid\n",
    "        else:\n",
    "            return res[0]\n",
    "    \n",
    "    def addtoindex(self, url, soup):\n",
    "        if self.indexed(url): return\n",
    "        print 'Indexing ' + url\n",
    "        \n",
    "        text = self.gettextonly(soup)\n",
    "        words = self.separatewords(text)\n",
    "        \n",
    "        urlid = self.getentryid('urllist', 'url', url)\n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in ignorewords: continue\n",
    "            wordid = self.getentryid('wordlist', 'word', word)\n",
    "            self.con.execute('insert into wordlocation(urlid, wordid, location) values (%d, %d, %d)' % (urlid, wordid, i))\n",
    "        \n",
    "    def gettextonly(self, soup):\n",
    "        v = soup.string\n",
    "        if v == None:\n",
    "            c = soup.contents\n",
    "            resulttext = ' '\n",
    "            for t in c:\n",
    "                subtext = self.gettextonly(t)\n",
    "                resulttext += subtext +'\\n'\n",
    "            return resulttext\n",
    "        else:\n",
    "            return v.strip()\n",
    "        \n",
    "    def separatewords(self, text):\n",
    "        splitter = re.compile('\\\\w*')\n",
    "        return [s.lower() for s in splitter.split(text) if s != ' ']\n",
    "    \n",
    "    def isindexed(self, url):\n",
    "        u = self.con.execute(\"select rowid from urllist where url = '%s' \" % url).fetchone()\n",
    "        if u != None:\n",
    "            v = self.con.execute('select * from wordlocation where urlid = %d' % u[0]).fetchone()\n",
    "            if v != None: return True\n",
    "        return False\n",
    "    \n",
    "    def addlinkref(self, urlForm, urlTo, linkText):\n",
    "        pass\n",
    "    \n",
    "    def crawl(self, pages, depth = 2):\n",
    "        for i in range(depth):\n",
    "            newpages = set()\n",
    "            for page in pages:\n",
    "                try:\n",
    "                    c = urllib2.urlopen(page)\n",
    "                except:\n",
    "                    print 'Could not open %s' % page\n",
    "                    continue\n",
    "                soup = BeautifulSoup(c.read())\n",
    "                self.addtoindex(page, soup)\n",
    "                    \n",
    "                links = soup('a')\n",
    "                for link in links:\n",
    "                    if ('href' in dict(link.attrs)):\n",
    "                        url = urljoin(page, link['href'])\n",
    "                        if url.find(\" ' \") != -1:continue\n",
    "                        url = url.split('#')[0]\n",
    "                        if url[0:4] == 'http' and not self.isindexed(url):\n",
    "                            newpages.add(url)\n",
    "                        linkText = self.gettextonly(link)\n",
    "                        self.addlinkref(page, url, linkText)\n",
    "                            \n",
    "                self.dbcommit()\n",
    "            pages = newpages\n",
    "            \n",
    "    def createindextables(self):\n",
    "        self.con.execute('create table urllist(url)')\n",
    "        self.con.execute('create table wordlist(word)')\n",
    "        self.con.execute('create table wordlocation(urlid, wordid, location)')\n",
    "        self.con.execute('create table link(fromid integer, toid integer)')\n",
    "        self.con.execute('create table linkwords(wordid, linkid)')\n",
    "        self.con.execute('create index wordidx on wordlist(word)')\n",
    "        self.con.execute('create index urlidx on urllist(url)')\n",
    "        self.con.execute('create index wordurlidx on wordlocation(wordid)')\n",
    "        self.con.execute('create index urltoidx on link(toid)')\n",
    "        self.con.execute('create index urlfromidx on link(fromid)')\n",
    "        self.dbcommit()\n",
    "        \n",
    "    def calculatepagerank(self, iterations = 20):\n",
    "        self.con.execute('drop table if exists pagerank')\n",
    "        self.con.execute('create table pagerank(urlid primary key,score)')\n",
    "        self.con.execute('insert into pagerank select rowid, 1.0 from urllist')\n",
    "        self.dbcommit()\n",
    "        for i in range(iterations):\n",
    "            print \"Iteration %d\" % (i)\n",
    "            for (urlid, ) in self.con.execute('select rowid from urllist'):\n",
    "                pr = 0.15\n",
    "                for (linker, )in self.con.execute('select distinct fromid from link where toid = %d' % urlid):\n",
    "                    linkingpr = self.con.execute('select score from pagerank where urlid = %d' % linker).fetchone()[0]\n",
    "                    linkingcount = self.con.execute('select count(*) from link where fromid = %d' % linker).fetchone()[0]\n",
    "                    pr += 0.85 * (linkingpr / linkingcount)\n",
    "                self.con.execute('update pagerank set score=%f where urlid=%d' % (pr, urlid))\n",
    "            self.dbcommit()\n",
    "\n",
    "class searcher:\n",
    "    def __init__(self, dbname):\n",
    "        self.con = sqlite.connect(dbname)\n",
    "    def __del__(self):\n",
    "        self.con.close()\n",
    "    \n",
    "    def getmatchrows(self, q):\n",
    "        fieldlist = 'w0.urlid'\n",
    "        tablelist = ' '\n",
    "        clauselist = ' '\n",
    "        wordids = []\n",
    "        \n",
    "        words = q.split(' ')\n",
    "        tablenumber = 0\n",
    "        \n",
    "        for word in words:\n",
    "            wordrow = self.con.execute(\"select rowid from wordlist where word = '%s' \" % word).fetchone()\n",
    "            if wordrow != None:\n",
    "                wordid = wordrow[0]\n",
    "                wordids.append(wordid)\n",
    "                if tablenumber > 0:\n",
    "                    tablelist += ','\n",
    "                    clauselist += ' and '\n",
    "                    clauselist += 'w%d.urlid = w%d.urlid and ' % (tablenumber - 1, tablenumber)\n",
    "                fieldlist += ',w%d.location' % tablenumber\n",
    "                tablelist += 'wordlocation w%d' % tablenumber\n",
    "                clauselist += 'w%d.wordid = %d' % (tablenumber, wordid)\n",
    "                tablenumber += 1\n",
    "        fullquery = 'select %s from %s where %s' % (fieldlist, tablelist, clauselist)\n",
    "        cur = self.con.execute(fullquery)\n",
    "        rows = [row for row in cur]\n",
    "        return rows, wordids\n",
    "    \n",
    "    def getscoredlist(self, rows, wordids):\n",
    "        totalscores = dict([(row[0], 0) for row in rows])\n",
    "        weights = [(1.0, self.locationscore(rows)),\n",
    "                          (1.0, self.frequencyscore(rows)),\n",
    "                          (1.0, self.pagerankscore(rows))]\n",
    "        for (weight, scores) in weights:\n",
    "            for url in totalscores:\n",
    "                totalscores[url] += weight * scores[url]\n",
    "        return totalscores\n",
    "    \n",
    "    def geturlname(self, id):\n",
    "        return self.con.execute(\"select url from urllist where rowid = %d\" % id).fetchone()[0]\n",
    "    \n",
    "    def query(self, q):\n",
    "        rows, wordids = self.getmatchrows(q)\n",
    "        scores = self.getscoredlist(rows, wordids)\n",
    "        rankedscores = sorted([(score, url) for (url, score) in scores.items()], reverse = 1)\n",
    "        for (score, urlid) in rankedscores[0:10]:\n",
    "            print '%f\\t%s' % (score, self.geturlname(urlid))\n",
    "   \n",
    "    def normalizescores(self, scores, smallIsBetter = 0):\n",
    "        vsmall = 0.00001\n",
    "        if smallIsBetter:\n",
    "            minscore = min(scores.values())\n",
    "            return dict([(u, float(minscore) / max(vsmall, l)) for (u, l) in scores.items()])\n",
    "        else:\n",
    "            maxscore = max(scores.values())\n",
    "            if maxscore ==0: maxscore = vsmall\n",
    "            return dict([(u, float(c) / maxscore) for (u, c) in scores.items()])\n",
    "     \n",
    "    def frequencyscore(self, rows):\n",
    "        counts = dict([(row[0], 0) for row in rows])\n",
    "        for row in rows: counts[row[0]] += 1\n",
    "        return self.normalizescores(counts)\n",
    "    \n",
    "    def locationscore(self, rows):\n",
    "        locations = dict([(row[0], 1000000) for row in rows])\n",
    "        for row in rows:\n",
    "            loc = sum(row[1:])\n",
    "            if loc < locations[row[0]]: locations[row[0]] = loc\n",
    "        return self.normalizescores(locations, smallIsBetter = 1)\n",
    "    \n",
    "    def distancescore(self, rows):\n",
    "        if len(row[0]) <= 2: return dict([(row[0], 1.0) for row in rows])\n",
    "        mindistance = dict([(row[0], 1000000) for row in rows])\n",
    "        for row in rows:\n",
    "            dist = sum([abs(row[i] - row[i - 1]) for i in range(2, len(row))])\n",
    "            if dist < mindistance[row[0]]: mindistance[row[0]] = dist\n",
    "        return self.normalizescores(mindistance, smallIsBetter = 1)\n",
    "    \n",
    "    def inboundlinkscore(self, rows):\n",
    "        uniqueurls = set([row[0] for row in rows])\n",
    "        inboundcount = dict([(u, self.con.execute('select count(*) from link where toid=%d' % u).fetchone()[0]) for u in uniqueurls])\n",
    "        return self.normalizescores(inboundcount)\n",
    "    \n",
    "    def pagerankscore(self, rows):\n",
    "        pageranks = dict([(row[0], self.con.execute('select score from pagerank where urlid=%d' % row[0]).fetchone()[0]) for row in rows])\n",
    "        maxrank = max(pageranks.values())\n",
    "        normalizedscores = dict([(u, float(l) / maxrank) for (u, l) in pageranks.items()])\n",
    "        return normalizedscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.318146\thttp://kiwitobes.com/wiki/Functional_programming.html\n",
      "1.074506\thttp://kiwitobes.com/wiki/Programming_language.html\n",
      "0.517633\thttp://kiwitobes.com/wiki/Categorical_list_of_programming_languages.html\n",
      "0.439568\thttp://kiwitobes.com/wiki/Programming_paradigm.html\n",
      "0.426817\thttp://kiwitobes.com/wiki/Lisp_programming_language.html\n",
      "0.400361\thttp://kiwitobes.com/wiki/Object-oriented_programming.html\n",
      "0.400066\thttp://kiwitobes.com/wiki/Haskell_programming_language.html\n",
      "0.368118\thttp://kiwitobes.com/wiki/Multi-paradigm_programming_language.html\n",
      "0.358329\thttp://kiwitobes.com/wiki/Scheme_programming_language.html\n",
      "0.336089\thttp://kiwitobes.com/wiki/Procedural_programming.html\n"
     ]
    }
   ],
   "source": [
    "e = searcher('searchindex.db')\n",
    "e.query('functional programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
